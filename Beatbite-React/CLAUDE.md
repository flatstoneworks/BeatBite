# Beatbite-React - CLAUDE.md

Voice-to-music creation app (React version) - making the next billion musicians.

## Project Overview

React/TypeScript implementation of Beatbite, designed for easy conversion to React Native. Uses Web Audio API for browser-based audio processing.

**Vision**: Instagram democratized photography with filters. Beatbite democratizes music creation using voice as the only input.

## Current Status: Prototype v0.2

Multi-instrument voice-to-music creation with loop recording, library management, and band system. All audio via Web Audio API with Tone.js samplers for realistic instrument sounds.

**Target Latency**: < 15ms (imperceptible) to max 100ms (acceptable)

## Development

### Prerequisites

- Node.js 18+
- Modern browser with Web Audio API support
- Headphones connected to device

### Quick Start

```bash
# Install dependencies
npm install

# Start development server (http://spark.local:9020)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview

# Type checking
npm run typecheck
```

### Port Configuration

| Port | Service |
|------|---------|
| 9020 | Development server |
| 9021 | API server (future) |
| 9022 | WebSocket server (future) |

## Architecture

```
src/
â”œâ”€â”€ main.tsx                           # App entry point
â”œâ”€â”€ App.tsx                            # Router + screen composition
â”œâ”€â”€ index.css                          # Tailwind CSS styles
â”œâ”€â”€ vite-env.d.ts                      # Vite types + __LOG_LEVEL__ declaration
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts                       # All TypeScript types (instruments, styles, configs)
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ useGuidedFlow.ts               # Guided recording flow hook
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ AudioEngine.ts                 # Web Audio API wrapper (mic, passthrough, effects, detection)
â”‚   â”œâ”€â”€ store.ts                       # Legacy re-export (â†’ store/index.ts)
â”‚   â”œâ”€â”€ store/                         # Zustand state management (split slices)
â”‚   â”‚   â”œâ”€â”€ index.ts                   # Main store + hooks
â”‚   â”‚   â”œâ”€â”€ create.ts                  # Store creation with all slices
â”‚   â”‚   â”œâ”€â”€ types.ts                   # Store type definitions
â”‚   â”‚   â”œâ”€â”€ selectors.ts              # Memoized selectors
â”‚   â”‚   â”œâ”€â”€ audioSlice.ts             # Audio state (passthrough, latency, effects)
â”‚   â”‚   â”œâ”€â”€ bandSlice.ts              # Band management state
â”‚   â”‚   â”œâ”€â”€ instrumentSlice.ts        # Instrument config state
â”‚   â”‚   â”œâ”€â”€ librarySlice.ts           # Song library state
â”‚   â”‚   â”œâ”€â”€ looperSlice.ts            # Loop recording state
â”‚   â”‚   â”œâ”€â”€ navigationSlice.ts        # Navigation state
â”‚   â”‚   â””â”€â”€ playbackSlice.ts          # Playback state
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ audioUtils.ts              # Shared DSP utilities (ADSR, type guards)
â”‚   â”‚   â””â”€â”€ logger.ts                  # Level-gated logger (debug/info/warn/error)
â”‚   â”œâ”€â”€ synthesizers/                  # Instrument synthesis (abstract hierarchy)
â”‚   â”‚   â”œâ”€â”€ AbstractSynthesizer.ts     # Base class (init, gain, audio context)
â”‚   â”‚   â”œâ”€â”€ MonophonicSynthesizer.ts   # Single-voice (bass, guitar)
â”‚   â”‚   â”œâ”€â”€ PianoSynthesizer.ts        # Polyphonic piano
â”‚   â”‚   â”œâ”€â”€ BassSynthesizer.ts         # Bass synthesis (sub, pluck, wobble)
â”‚   â”‚   â”œâ”€â”€ GuitarSynthesizer.ts       # Guitar synthesis (clean, distorted, acoustic)
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ demoPlayers/                   # Instrument demo playback (abstract hierarchy)
â”‚   â”‚   â”œâ”€â”€ AbstractDemoPlayer.ts      # Base class (init, BPM, beat loop, volume, sampler)
â”‚   â”‚   â”œâ”€â”€ BassDemoPlayer.ts          # Bass demo (electronic + sampled styles)
â”‚   â”‚   â”œâ”€â”€ GuitarDemoPlayer.ts        # Guitar demo (electronic + sampled + electric)
â”‚   â”‚   â”œâ”€â”€ PianoDemoPlayer.ts         # Piano demo (electronic + sampled styles)
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ BassDemoPlayer.ts             # Re-export proxy â†’ demoPlayers/
â”‚   â”œâ”€â”€ GuitarDemoPlayer.ts           # Re-export proxy â†’ demoPlayers/
â”‚   â”œâ”€â”€ PianoDemoPlayer.ts            # Re-export proxy â†’ demoPlayers/
â”‚   â”œâ”€â”€ LayerManager.ts               # Multi-track layer management
â”‚   â”œâ”€â”€ LayerRecorder.ts              # Single layer recording
â”‚   â”œâ”€â”€ LoopRecorder.ts               # Loop-based recording
â”‚   â”œâ”€â”€ TransportController.ts        # Playback transport (tempo, loop boundaries)
â”‚   â”œâ”€â”€ MetronomeAudio.ts             # Click track
â”‚   â”œâ”€â”€ Quantizer.ts                  # Note quantization
â”‚   â”œâ”€â”€ LoopQuantizer.ts              # Loop-level quantization
â”‚   â”œâ”€â”€ DrumSynthesizer.ts            # Electronic drum synthesis
â”‚   â”œâ”€â”€ SampledDrumKit.ts             # Tone.js sampled drum kit
â”‚   â”œâ”€â”€ DrumKitPlayer.ts              # Drum playback controller
â”‚   â”œâ”€â”€ DrumEventPlayer.ts            # Drum event sequence player
â”‚   â”œâ”€â”€ DrumEventRecorder.ts          # Drum event recorder
â”‚   â”œâ”€â”€ MelodicEventPlayer.ts         # Melodic event sequence player
â”‚   â”œâ”€â”€ MelodicEventRecorder.ts       # Melodic event recorder
â”‚   â”œâ”€â”€ BaseSamplerInstrument.ts      # Base Tone.js sampler (shared by all samplers)
â”‚   â”œâ”€â”€ RealisticBassSampler.ts       # Tone.js bass sampler
â”‚   â”œâ”€â”€ RealisticGuitarSampler.ts     # Tone.js guitar sampler
â”‚   â”œâ”€â”€ RealisticPianoSampler.ts      # Tone.js piano sampler
â”‚   â”œâ”€â”€ ElectricGuitarSampler.ts      # Tone.js electric guitar sampler
â”‚   â”œâ”€â”€ BeatboxDetector.ts            # Voice â†’ drum detection (FFT + energy)
â”‚   â”œâ”€â”€ BpmDetector.ts                # Tempo detection
â”‚   â”œâ”€â”€ PitchDetector.ts              # Voice pitch detection (autocorrelation)
â”‚   â”œâ”€â”€ VoiceOnsetDetector.ts         # Voice onset/offset detection
â”‚   â”œâ”€â”€ VoiceEffects.ts               # Reverb, delay, chorus, distortion
â”‚   â”œâ”€â”€ RecordingStorage.ts           # IndexedDB storage for recordings
â”‚   â”œâ”€â”€ LibraryStorage.ts             # IndexedDB storage for song library
â”‚   â””â”€â”€ BandStorage.ts                # localStorage band persistence
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”œâ”€â”€ BandSelectionScreen.tsx    # Band picker
â”‚   â”‚   â”œâ”€â”€ BandCreateScreen.tsx       # Band creation with instrument demos
â”‚   â”‚   â”œâ”€â”€ BandEditScreen.tsx         # Band editing
â”‚   â”‚   â”œâ”€â”€ BandNameScreen.tsx         # Band naming
â”‚   â”‚   â”œâ”€â”€ InstrumentSetupScreen.tsx  # Instrument config + style selection
â”‚   â”‚   â”œâ”€â”€ TempoSelectorScreen.tsx    # Tempo selection
â”‚   â”‚   â”œâ”€â”€ RecordScreen.tsx           # Main recording screen
â”‚   â”‚   â”œâ”€â”€ RecordingScreen.tsx        # Active recording session
â”‚   â”‚   â”œâ”€â”€ GuidedRecordingScreen.tsx  # Step-by-step guided recording
â”‚   â”‚   â”œâ”€â”€ LooperScreen.tsx           # Loop-based recording
â”‚   â”‚   â”œâ”€â”€ LibraryScreen.tsx          # Song library browser
â”‚   â”‚   â”œâ”€â”€ PassthroughScreen.tsx      # Latency test screen
â”‚   â”‚   â””â”€â”€ SettingsScreen.tsx         # App settings
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ index.ts                   # Component barrel exports
â”‚       â”œâ”€â”€ AudioVisualizer.tsx        # Level visualization
â”‚       â”œâ”€â”€ LatencyDisplay.tsx         # Latency indicator
â”‚       â”œâ”€â”€ VolumeSlider.tsx           # Netflix-style slider
â”‚       â”œâ”€â”€ FlowHeader.tsx             # Screen header with breadcrumbs
â”‚       â”œâ”€â”€ FooterNav.tsx              # Bottom navigation
â”‚       â”œâ”€â”€ ActiveBandHeader.tsx       # Current band display
â”‚       â”œâ”€â”€ MiniPlayer.tsx             # Compact song player
â”‚       â”œâ”€â”€ FullScreenPlayer.tsx       # Full screen playback
â”‚       â”œâ”€â”€ RecordingPanel.tsx         # Recording controls
â”‚       â”œâ”€â”€ EffectsPanel.tsx           # Effects controls
â”‚       â”œâ”€â”€ InstrumentOptionCard.tsx   # Instrument style card
â”‚       â”œâ”€â”€ DrumIndicator.tsx          # Drum beat indicator
â”‚       â”œâ”€â”€ BassIndicator.tsx          # Bass note indicator
â”‚       â”œâ”€â”€ GuitarIndicator.tsx        # Guitar note indicator
â”‚       â”œâ”€â”€ PianoIndicator.tsx         # Piano note indicator
â”‚       â”œâ”€â”€ PitchDisplay.tsx           # Pitch visualization
â”‚       â””â”€â”€ Icons.tsx                  # SVG icon components
â””â”€â”€ vite.config.ts                     # Vite config (HTTPS, aliases, __LOG_LEVEL__)
```

## Core Components

### AudioEngine (`src/core/AudioEngine.ts`)

Central Web Audio API wrapper â€” handles mic input, passthrough, effects chain, detection dispatch, and synthesis routing.

### State Management (`src/core/store/`)

Zustand store split into domain slices for maintainability:

| Slice | Responsibilities |
|-------|-----------------|
| `audioSlice` | Passthrough, latency, effects, mic permissions |
| `bandSlice` | Band CRUD, active band, instrument config |
| `instrumentSlice` | Instrument types, styles, synth types |
| `librarySlice` | Song library, save/load/delete |
| `looperSlice` | Loop recording state, layers |
| `navigationSlice` | Screen navigation, flow state |
| `playbackSlice` | Transport, BPM, play/stop |

### Logger (`src/core/utils/logger.ts`)

Level-gated logging utility. Replaces all raw `console.*` calls.

```typescript
import { logger } from '@/core/utils/logger';

logger.debug('per-frame data');   // Only in dev (stripped in prod)
logger.info('lifecycle event');    // Only in dev (stripped in prod)
logger.warn('non-critical issue'); // Always shown
logger.error('failure', error);    // Always shown
```

Levels controlled by Vite `define` â€” `__LOG_LEVEL__` is `"debug"` in dev, `"warn"` in production. **Never use raw `console.log/warn/error`** â€” always use `logger`.

### Synthesizer Hierarchy (`src/core/synthesizers/`)

```
AbstractSynthesizer          â€” init, gain, audio context management
  â”œâ”€â”€ MonophonicSynthesizer  â€” single-voice (bass, guitar)
  â”‚   â”œâ”€â”€ BassSynthesizer    â€” sub, pluck, wobble synthesis
  â”‚   â””â”€â”€ GuitarSynthesizer  â€” clean, distorted, acoustic synthesis
  â””â”€â”€ PianoSynthesizer       â€” polyphonic with harmonic table
```

### DemoPlayer Hierarchy (`src/core/demoPlayers/`)

Instrument demo playback for setup/preview screens. Singletons exported from `index.ts`.

```
AbstractDemoPlayer           â€” init, BPM loop, volume, sampler loading
  â”œâ”€â”€ BassDemoPlayer         â€” 2 synth types (electronic/sampled), 4 electronic styles
  â”œâ”€â”€ GuitarDemoPlayer       â€” 3 synth types (+electric sampler), 4 electronic styles
  â””â”€â”€ PianoDemoPlayer        â€” 2 synth types, 5 electronic styles with harmonic table
```

**Backward-compatible proxies**: `src/core/BassDemoPlayer.ts`, `GuitarDemoPlayer.ts`, `PianoDemoPlayer.ts` re-export from `demoPlayers/`. Consumer files import from these proxies â€” no need to update imports.

### Samplers (Tone.js)

| Sampler | File | Purpose |
|---------|------|---------|
| `RealisticBassSampler` | `RealisticBassSampler.ts` | Sampled bass with multiple styles |
| `RealisticGuitarSampler` | `RealisticGuitarSampler.ts` | Sampled acoustic guitar |
| `ElectricGuitarSampler` | `ElectricGuitarSampler.ts` | Sampled electric guitar |
| `RealisticPianoSampler` | `RealisticPianoSampler.ts` | Sampled piano with multiple styles |
| `SampledDrumKit` | `SampledDrumKit.ts` | Sampled drum kit |
| `BaseSamplerInstrument` | `BaseSamplerInstrument.ts` | Shared base for all Tone.js samplers |

### Detection

| Detector | Purpose |
|----------|---------|
| `BeatboxDetector` | Voice â†’ drum mapping (FFT + energy analysis) |
| `PitchDetector` | Voice frequency detection (autocorrelation) |
| `VoiceOnsetDetector` | Voice onset/offset events |
| `BpmDetector` | Tempo detection from audio |

### Recording & Playback

| Module | Purpose |
|--------|---------|
| `LayerManager` | Multi-track layer management (add, remove, play all) |
| `LayerRecorder` | Single layer recording with loop-boundary sync |
| `LoopRecorder` | Loop-based recording and playback |
| `TransportController` | Tempo, loop boundaries, play/stop |
| `MetronomeAudio` | Click track |
| `Quantizer` / `LoopQuantizer` | Note and loop quantization |
| `DrumEventRecorder/Player` | Drum event sequence record/playback |
| `MelodicEventRecorder/Player` | Melodic event sequence record/playback |

### Storage

| Module | Backend | Purpose |
|--------|---------|---------|
| `RecordingStorage` | IndexedDB | Recording sessions, voice audio, mixes |
| `LibraryStorage` | IndexedDB | Song library (save, load, delete, rename) |
| `BandStorage` | localStorage | Band config persistence |

## React Native Migration

This codebase is designed for easy conversion to React Native:

### What Changes

1. **AudioEngine.ts** â†’ Replace Web Audio API with:
   - `react-native-audio-api` (experimental)
   - `expo-av` for basic audio
   - Native modules for low-latency (recommended)

2. **UI Components** â†’ Replace HTML elements with:
   - `View` instead of `div`
   - `Text` instead of `span`/`p`
   - `Pressable` instead of pointer events
   - React Native SVG for icons

3. **Styling** â†’ Replace Tailwind with:
   - `nativewind` (Tailwind for RN)
   - StyleSheet objects
   - Keep same color values

### What Stays the Same

- Zustand store (`src/core/store.ts`)
- Types (`src/types/index.ts`)
- Component logic and state
- File structure

### Native Audio Bridge

For React Native with low-latency audio, you'll need native modules:

**Android (Kotlin)**:
- Use `AudioRecord` + `AudioTrack`
- Or [Oboe](https://github.com/google/oboe) for better performance

**iOS (Swift)**:
- Use `AVAudioEngine`
- Configure `AVAudioSession` for low latency

## Testing Latency

1. Open `http://spark.local:9020` in a modern browser
2. Connect wired headphones (Bluetooth adds latency)
3. Click/touch and hold anywhere on screen
4. Speak into the microphone
5. Observe the latency display

**Latency Quality**:
- ðŸŸ¢ < 15ms: Excellent (imperceptible)
- ðŸŸ¡ 15-50ms: Good
- ðŸŸ  50-100ms: Acceptable
- ðŸ”´ > 100ms: Problematic

## User Experience Principles

1. **Instant Feedback**: Real-time audio response while singing
2. **Touch-Based**: Hold to record, slide for volume (Netflix-style)
3. **Loop Recording**: WhatsApp-style press-to-record
4. **Auto-Save**: Google Docs-style automatic saving
5. **Dark UI**: Minimalist dark interface

## Development Progress

### Phase 1: Web Prototype (Complete)
- [x] Audio passthrough with latency testing
- [x] Pitch detection (autocorrelation)
- [x] Beatbox detection (FFT + energy)
- [x] Voice onset/offset detection
- [x] BPM detection
- [x] Drum synthesis (electronic + sampled kit)
- [x] Bass synthesis (electronic + sampled, 4 styles)
- [x] Guitar synthesis (electronic + sampled + electric, 4 styles)
- [x] Piano synthesis (electronic + sampled, 5 styles)
- [x] Voice effects (reverb, delay, chorus, distortion)
- [x] Loop recording and playback
- [x] Multi-layer recording with loop-boundary sync
- [x] Quantization
- [x] Band system (create, edit, instrument config)
- [x] Song library with IndexedDB storage
- [x] Guided recording flow

### Phase 2: Structural Refactoring (Complete)
- [x] LayerManager extraction
- [x] Synthesizer abstract hierarchy
- [x] Zustand store split into domain slices
- [x] DemoPlayer deduplication (AbstractDemoPlayer)
- [x] Logger utility with production stripping

### Next: React Native Migration
- [ ] Port to React Native (see Migration Guide below)
- [ ] Native audio modules (Kotlin/Swift)
- [ ] iOS/Android builds

## Key Dependencies

- **React 18** + **React Router DOM** â€” UI framework + routing
- **Zustand** â€” State management (RN compatible)
- **Tone.js** â€” Sampled instrument playback (piano, bass, guitar, drums)
- **Tailwind CSS** â€” Styling (nativewind for RN)
- **Vite** â€” Build tool with `define` for compile-time constants
- **TypeScript** â€” Type safety
- **Web Audio API** â€” Browser audio (native modules for RN)
- **Playwright** â€” E2E testing (dev dependency)
- **clsx** â€” Conditional className utility

## Conventions

### Logging
- **Never** use raw `console.log/warn/error` â€” use `logger.debug/info/warn/error` from `@/core/utils/logger`
- **Hot paths** (per-frame, per-note, per-beat): `logger.debug` â€” stripped in production
- **Lifecycle events** (init, start, stop, loaded): `logger.info` â€” stripped in production
- **Warnings** (non-critical): `logger.warn` â€” always shown
- **Errors** (failures, catch blocks): `logger.error` â€” always shown

### Class Hierarchies
- Synthesizers extend `AbstractSynthesizer` (in `synthesizers/`)
- DemoPlayers extend `AbstractDemoPlayer` (in `demoPlayers/`)
- Both use template method pattern with abstract hooks

### Backward Compatibility
- Old file locations (`src/core/BassDemoPlayer.ts`, etc.) are 1-line re-export proxies
- Consumer files import from these proxies â€” **do not delete proxy files**
- `src/core/store.ts` is a re-export proxy for `src/core/store/index.ts`

### Commit Convention
`[type][Domain] Description` â€” e.g., `[refactor][Core] Add logger utility`

## Performance Notes

### Web Audio API
- Use `latencyHint: 'interactive'` for lowest latency
- Disable echo cancellation/noise suppression
- Use small buffer sizes (256 samples)
- Check `baseLatency` and `outputLatency` properties

### Browser Compatibility
- Chrome: Best Web Audio API support
- Firefox: Good support
- Safari: May have higher latency
- Mobile browsers: Variable support

## Resources

- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [Zustand](https://github.com/pmndrs/zustand)
- [Tailwind CSS](https://tailwindcss.com/)
- [React Native Audio API](https://github.com/software-mansion/react-native-audio-api)

---

## React Native Migration Guide

This section documents the approach for migrating Beatbite-React to React Native when ready.

### Overview

The React codebase is designed for straightforward migration to React Native. The key insight: **audio processing must be native** for acceptable latency (<25ms), but **state management, types, and component logic can remain largely unchanged**.

### Migration Layers

| Layer | React (Web) | React Native | Migration Effort |
|-------|-------------|--------------|------------------|
| **Audio Engine** | Web Audio API | Native modules (Kotlin/Swift) | **High** - Complete rewrite |
| **State Management** | Zustand | Zustand (identical) | **None** |
| **Types** | TypeScript | TypeScript (identical) | **None** |
| **UI Components** | JSX + Tailwind | RN components + NativeWind | **Medium** - Syntax changes |
| **Storage** | IndexedDB | AsyncStorage/SQLite | **Low** |

### What Stays the Same

These files can be copied with minimal or no changes:

```
src/
â”œâ”€â”€ core/
â”‚   â””â”€â”€ store.ts              # Zustand store - identical API
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts              # TypeScript types - identical
â””â”€â”€ [component logic]         # State, hooks, business logic
```

### What Changes

#### 1. Audio Engine â†’ Native Bridge

The Web Audio API (`AudioEngine.ts`) must be replaced with native modules.

**Create an AudioBridge abstraction:**

```typescript
// src/core/AudioBridge.ts
import { NativeModules, NativeEventEmitter } from 'react-native';

const { BeatbiteAudio } = NativeModules;
const audioEmitter = BeatbiteAudio ? new NativeEventEmitter(BeatbiteAudio) : null;

export const AudioBridge = {
  isNativeAvailable: (): boolean => BeatbiteAudio != null,

  initialize: async (): Promise<boolean> => {
    if (BeatbiteAudio) return BeatbiteAudio.initialize();
    console.log('[Mock] initialize');
    return true;
  },

  startPassthrough: async (): Promise<void> => {
    if (BeatbiteAudio) return BeatbiteAudio.startPassthrough();
  },

  stopPassthrough: async (): Promise<void> => {
    if (BeatbiteAudio) return BeatbiteAudio.stopPassthrough();
  },

  // Effects
  toggleEffect: (effect: EffectType, enabled: boolean): void => {
    BeatbiteAudio?.toggleEffect(effect, enabled);
  },

  setEffectParam: (effect: EffectType, param: string, value: number): void => {
    BeatbiteAudio?.setEffectParam(effect, param, value);
  },

  // Synthesizers
  setDrumKit: (kit: DrumKitType): void => BeatbiteAudio?.setDrumKit(kit),
  triggerDrum: (drum: string, velocity: number): void => BeatbiteAudio?.triggerDrum(drum, velocity),
  setBassStyle: (style: BassStyle): void => BeatbiteAudio?.setBassStyle(style),
  triggerBassNote: (freq: number, velocity: number): void => BeatbiteAudio?.triggerBassNote(freq, velocity),
  setGuitarStyle: (style: GuitarStyle): void => BeatbiteAudio?.setGuitarStyle(style),
  triggerGuitarNote: (freq: number, velocity: number): void => BeatbiteAudio?.triggerGuitarNote(freq, velocity),

  // Detection
  setBeatboxEnabled: (enabled: boolean): void => BeatbiteAudio?.setBeatboxEnabled(enabled),
  setPitchEnabled: (enabled: boolean): void => BeatbiteAudio?.setPitchEnabled(enabled),

  // Event listeners
  onLevelChanged: (callback: (level: number) => void) => {
    return audioEmitter?.addListener('onLevelChanged', callback);
  },
  onBeatDetected: (callback: (data: { drum: string; velocity: number }) => void) => {
    return audioEmitter?.addListener('onBeatDetected', callback);
  },
  onPitchDetected: (callback: (data: { frequency: number; confidence: number }) => void) => {
    return audioEmitter?.addListener('onPitchDetected', callback);
  },
  onLatencyMeasured: (callback: (latency: number) => void) => {
    return audioEmitter?.addListener('onLatencyMeasured', callback);
  },
};
```

#### 2. Native Module Structure (Android)

```
android/app/src/main/java/com/beatbite/audio/
â”œâ”€â”€ BeatbiteAudioModule.kt      # React Native bridge (exposes methods to JS)
â”œâ”€â”€ BeatbiteAudioPackage.kt     # Module registration
â”œâ”€â”€ AudioEngine.kt              # Core AAudio stream management
â”œâ”€â”€ AudioGraph.kt               # Audio routing/mixing
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ VoiceProcessor.kt       # Mic â†’ effects â†’ output
â”‚   â”œâ”€â”€ ReverbProcessor.kt      # Convolution/algorithmic reverb
â”‚   â”œâ”€â”€ DelayProcessor.kt       # Delay/echo effect
â”‚   â”œâ”€â”€ ChorusProcessor.kt      # Chorus/modulation
â”‚   â””â”€â”€ DistortionProcessor.kt  # Waveshaper distortion
â”œâ”€â”€ synthesizers/
â”‚   â”œâ”€â”€ DrumSynthesizer.kt      # Kick, snare, hihat synthesis
â”‚   â”œâ”€â”€ BassSynthesizer.kt      # Bass synthesis
â”‚   â””â”€â”€ GuitarSynthesizer.kt    # Guitar (Karplus-Strong)
â”œâ”€â”€ detectors/
â”‚   â”œâ”€â”€ BeatboxDetector.kt      # FFT + energy analysis
â”‚   â””â”€â”€ PitchDetector.kt        # Autocorrelation/YIN
â””â”€â”€ utils/
    â”œâ”€â”€ AudioBuffer.kt          # Ring buffer
    â””â”€â”€ AudioUtils.kt           # DSP utilities
```

#### 3. AAudio Implementation (Android)

Target: **<25ms round-trip latency**

```kotlin
// AudioEngine.kt
class AudioEngine {
    private var inputStream: AAudioStream? = null
    private var outputStream: AAudioStream? = null

    fun initialize(): Boolean {
        // Input stream (microphone)
        val inputBuilder = AAudioStreamBuilder()
            .setDirection(AAUDIO_DIRECTION_INPUT)
            .setSharingMode(AAUDIO_SHARING_MODE_EXCLUSIVE)  // Low latency
            .setPerformanceMode(AAUDIO_PERFORMANCE_MODE_LOW_LATENCY)
            .setSampleRate(48000)
            .setChannelCount(1)  // Mono input
            .setFormat(AAUDIO_FORMAT_PCM_FLOAT)
            .setBufferCapacityInFrames(256)  // ~5ms buffer
            .setDataCallback(inputCallback)

        // Output stream (speakers/headphones)
        val outputBuilder = AAudioStreamBuilder()
            .setDirection(AAUDIO_DIRECTION_OUTPUT)
            .setSharingMode(AAUDIO_SHARING_MODE_EXCLUSIVE)
            .setPerformanceMode(AAUDIO_PERFORMANCE_MODE_LOW_LATENCY)
            .setSampleRate(48000)
            .setChannelCount(2)  // Stereo output
            .setFormat(AAUDIO_FORMAT_PCM_FLOAT)
            .setBufferCapacityInFrames(256)

        inputStream = inputBuilder.build()
        outputStream = outputBuilder.build()
        return inputStream != null && outputStream != null
    }
}

// Audio processing callback
private val outputCallback = object : AAudioStreamDataCallback {
    override fun onAudioReady(stream: AAudioStream, audioData: FloatArray, numFrames: Int): Int {
        // 1. Read input from ring buffer
        val input = inputBuffer.read(numFrames)

        // 2. Process effects chain
        var processed = input
        if (reverbEnabled) processed = reverbProcessor.process(processed)
        if (delayEnabled) processed = delayProcessor.process(processed)
        if (chorusEnabled) processed = chorusProcessor.process(processed)

        // 3. Mix synthesizers
        val drums = drumSynthesizer.render(numFrames)
        val bass = bassSynthesizer.render(numFrames)
        val guitar = guitarSynthesizer.render(numFrames)

        // 4. Output stereo mix
        for (i in 0 until numFrames) {
            val mixed = processed[i] + drums[i] + bass[i] + guitar[i]
            audioData[i * 2] = mixed      // Left
            audioData[i * 2 + 1] = mixed  // Right
        }
        return AAUDIO_CALLBACK_RESULT_CONTINUE
    }
}
```

#### 4. Native Module Structure (iOS)

```
ios/BeatbiteAudio/
â”œâ”€â”€ BeatbiteAudioModule.swift   # React Native bridge
â”œâ”€â”€ BeatbiteAudioModule.m       # Objective-C bridge header
â”œâ”€â”€ AudioEngine.swift           # AVAudioEngine wrapper
â”œâ”€â”€ Processors/
â”‚   â”œâ”€â”€ ReverbProcessor.swift
â”‚   â”œâ”€â”€ DelayProcessor.swift
â”‚   â””â”€â”€ ChorusProcessor.swift
â””â”€â”€ Synthesizers/
    â”œâ”€â”€ DrumSynthesizer.swift
    â”œâ”€â”€ BassSynthesizer.swift
    â””â”€â”€ GuitarSynthesizer.swift
```

```swift
// AudioEngine.swift
import AVFoundation

class AudioEngine {
    private let engine = AVAudioEngine()
    private let inputNode: AVAudioInputNode
    private let outputNode: AVAudioOutputNode

    func initialize() throws {
        // Configure session for low latency
        let session = AVAudioSession.sharedInstance()
        try session.setCategory(.playAndRecord, options: [.defaultToSpeaker, .allowBluetooth])
        try session.setPreferredIOBufferDuration(0.005)  // 5ms buffer
        try session.setPreferredSampleRate(48000)
        try session.setActive(true)

        inputNode = engine.inputNode
        outputNode = engine.outputNode

        // Install tap on input
        let format = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 256, format: format) { buffer, time in
            self.processAudio(buffer: buffer)
        }

        try engine.start()
    }
}
```

#### 5. UI Components Mapping

| React (Web) | React Native | Notes |
|-------------|--------------|-------|
| `<div>` | `<View>` | |
| `<span>`, `<p>` | `<Text>` | All text must be in Text |
| `onClick` | `onPress` | Use Pressable |
| `className="..."` | `style={styles.x}` or NativeWind | |
| `<input>` | `<TextInput>` | |
| SVG | react-native-svg | |
| CSS transitions | Reanimated | |

**Example conversion:**

```tsx
// React (Web)
<div className="flex items-center gap-2 p-4 bg-gray-900 rounded-lg" onClick={handleClick}>
  <span className="text-white text-lg">{title}</span>
</div>

// React Native
<Pressable style={styles.container} onPress={handleClick}>
  <Text style={styles.title}>{title}</Text>
</Pressable>

const styles = StyleSheet.create({
  container: { flexDirection: 'row', alignItems: 'center', gap: 8, padding: 16, backgroundColor: '#111', borderRadius: 8 },
  title: { color: '#fff', fontSize: 18 },
});

// Or with NativeWind (Tailwind for RN)
<Pressable className="flex-row items-center gap-2 p-4 bg-gray-900 rounded-lg" onPress={handleClick}>
  <Text className="text-white text-lg">{title}</Text>
</Pressable>
```

#### 6. Storage Migration

```typescript
// React (Web) - IndexedDB
import { RecordingStorage } from './RecordingStorage';

// React Native - AsyncStorage or SQLite
import AsyncStorage from '@react-native-async-storage/async-storage';

// Simple adapter pattern
export const Storage = {
  save: async (key: string, data: any) => {
    await AsyncStorage.setItem(key, JSON.stringify(data));
  },
  load: async (key: string) => {
    const data = await AsyncStorage.getItem(key);
    return data ? JSON.parse(data) : null;
  },
};
```

### Migration Phases

#### Phase 1: Project Setup
- [ ] Initialize React Native project with Expo (managed workflow initially)
- [ ] Copy `store.ts` and `types/index.ts` unchanged
- [ ] Set up NativeWind for Tailwind CSS support
- [ ] Create AudioBridge with mock implementations

#### Phase 2: UI Migration
- [ ] Convert screens one by one (start with simplest)
- [ ] Use Pressable + StyleSheet or NativeWind
- [ ] Test UI in Expo Go (mock audio mode)

#### Phase 3: Native Audio (Android)
- [ ] Eject to bare workflow or use development build
- [ ] Implement BeatbiteAudioModule.kt bridge
- [ ] Implement AudioEngine.kt with AAudio
- [ ] Add basic passthrough
- [ ] Measure and optimize latency

#### Phase 4: Effects & Synthesizers (Android)
- [ ] Port effects (reverb, delay, chorus, distortion)
- [ ] Port drum synthesizer
- [ ] Port bass/guitar synthesizers
- [ ] Port detection (beatbox, pitch)

#### Phase 5: iOS Implementation
- [ ] Implement BeatbiteAudioModule.swift
- [ ] Port AudioEngine with AVAudioEngine
- [ ] Port effects and synthesizers
- [ ] Test and optimize latency

#### Phase 6: Recording & Playback
- [ ] Port layer recording system
- [ ] Port quantization
- [ ] Port transport controller
- [ ] Implement storage with AsyncStorage/SQLite

### Performance Guidelines

1. **Avoid allocations in audio callback** - Pre-allocate all buffers
2. **Keep callback fast** - Target <1ms processing time
3. **Use small buffers** - 256 frames at 48kHz = 5.3ms per buffer
4. **Use exclusive mode** - `AAUDIO_SHARING_MODE_EXCLUSIVE` for lowest latency
5. **Test with wired headphones** - Bluetooth adds 100-300ms latency

### Latency Targets

| Quality | Latency | User Experience |
|---------|---------|-----------------|
| Excellent | <15ms | Imperceptible |
| Good | 15-30ms | Slight delay, acceptable |
| Acceptable | 30-50ms | Noticeable but usable |
| Poor | >50ms | Distracting |

### Development Approach

**Recommended: Develop audio on native first**

1. Build native audio modules separately (pure Kotlin/Swift)
2. Test with simple native test app
3. Once latency is acceptable, integrate with React Native
4. Use mock mode for UI development (Expo Go compatible)

### Alternative: react-native-audio-api

[react-native-audio-api](https://github.com/software-mansion/react-native-audio-api) provides Web Audio API-like interface for React Native. This could simplify migration but may have higher latency than custom native modules. Consider for:
- Rapid prototyping
- Non-latency-critical features
- Fallback on devices where native fails

### Files to Migrate (Priority Order)

**Core (copy unchanged):**
1. `src/types/index.ts`
2. `src/core/store.ts`

**Create new:**
3. `src/core/AudioBridge.ts` (native interface)

**Convert UI:**
4. `src/ui/screens/` (one at a time)
5. `src/ui/components/` (as needed by screens)

**Port audio (native modules):**
6. Detection: PitchDetector, BeatboxDetector
7. Synthesizers: DrumSynthesizer, BassSynthesizer, GuitarSynthesizer
8. Effects: VoiceEffects
9. Recording: LayerRecorder, LoopRecorder, TransportController
10. Storage: RecordingStorage, LibraryStorage, BandStorage
